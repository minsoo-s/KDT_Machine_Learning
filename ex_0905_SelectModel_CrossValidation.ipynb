{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습: select_model\n",
    "---\n",
    "Sklearn 모델 추천 함수 활용\n",
    "- sklearn.utils 모듈의 all_estimators(type_filter)\n",
    "    * type_filter 파라미터: 'classifier','regressor' 지정\n",
    "    * 반환: 해당 타입의 모델 리스트 => 모델이름, 모델객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [1] 데이터 로딩 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bunch 데이터 타입 => dict와 유사한 형태\n",
    "data =load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, target => numpy 타입\n",
    "# target_names => 라벨 => setosa, versicolor...\n",
    "# feature_names => 컬럼명\n",
    "input_data = data['data']\n",
    "input_target = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [2] 학습 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 - 테스트 데이터셋\n",
    "train_input, test_input, train_target, test_target =train_test_split(input_data, input_target, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 - 검증용 데이터셋\n",
    "train_input, val_input, train_target, val_target =train_test_split(train_input, train_target, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [3] 학습\n",
    "- 학습방법 선정 => 분류/회귀\n",
    "    - 분류 => knn, logisticRegression, DecisionTreeClassifier, SGDClassifier,SVC...\n",
    "    - 분류모델 적용 후결과 => all_estimators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
       " ('BaggingClassifier', sklearn.ensemble._bagging.BaggingClassifier),\n",
       " ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
       " ('CalibratedClassifierCV', sklearn.calibration.CalibratedClassifierCV),\n",
       " ('CategoricalNB', sklearn.naive_bayes.CategoricalNB),\n",
       " ('ClassifierChain', sklearn.multioutput.ClassifierChain),\n",
       " ('ComplementNB', sklearn.naive_bayes.ComplementNB),\n",
       " ('DecisionTreeClassifier', sklearn.tree._classes.DecisionTreeClassifier),\n",
       " ('DummyClassifier', sklearn.dummy.DummyClassifier),\n",
       " ('ExtraTreeClassifier', sklearn.tree._classes.ExtraTreeClassifier),\n",
       " ('ExtraTreesClassifier', sklearn.ensemble._forest.ExtraTreesClassifier),\n",
       " ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
       " ('GaussianProcessClassifier',\n",
       "  sklearn.gaussian_process._gpc.GaussianProcessClassifier),\n",
       " ('GradientBoostingClassifier',\n",
       "  sklearn.ensemble._gb.GradientBoostingClassifier),\n",
       " ('HistGradientBoostingClassifier',\n",
       "  sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier),\n",
       " ('KNeighborsClassifier',\n",
       "  sklearn.neighbors._classification.KNeighborsClassifier),\n",
       " ('LabelPropagation',\n",
       "  sklearn.semi_supervised._label_propagation.LabelPropagation),\n",
       " ('LabelSpreading', sklearn.semi_supervised._label_propagation.LabelSpreading),\n",
       " ('LinearDiscriminantAnalysis',\n",
       "  sklearn.discriminant_analysis.LinearDiscriminantAnalysis),\n",
       " ('LinearSVC', sklearn.svm._classes.LinearSVC),\n",
       " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
       " ('LogisticRegressionCV', sklearn.linear_model._logistic.LogisticRegressionCV),\n",
       " ('MLPClassifier',\n",
       "  sklearn.neural_network._multilayer_perceptron.MLPClassifier),\n",
       " ('MultiOutputClassifier', sklearn.multioutput.MultiOutputClassifier),\n",
       " ('MultinomialNB', sklearn.naive_bayes.MultinomialNB),\n",
       " ('NearestCentroid', sklearn.neighbors._nearest_centroid.NearestCentroid),\n",
       " ('NuSVC', sklearn.svm._classes.NuSVC),\n",
       " ('OneVsOneClassifier', sklearn.multiclass.OneVsOneClassifier),\n",
       " ('OneVsRestClassifier', sklearn.multiclass.OneVsRestClassifier),\n",
       " ('OutputCodeClassifier', sklearn.multiclass.OutputCodeClassifier),\n",
       " ('PassiveAggressiveClassifier',\n",
       "  sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier),\n",
       " ('Perceptron', sklearn.linear_model._perceptron.Perceptron),\n",
       " ('QuadraticDiscriminantAnalysis',\n",
       "  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis),\n",
       " ('RadiusNeighborsClassifier',\n",
       "  sklearn.neighbors._classification.RadiusNeighborsClassifier),\n",
       " ('RandomForestClassifier', sklearn.ensemble._forest.RandomForestClassifier),\n",
       " ('RidgeClassifier', sklearn.linear_model._ridge.RidgeClassifier),\n",
       " ('RidgeClassifierCV', sklearn.linear_model._ridge.RidgeClassifierCV),\n",
       " ('SGDClassifier', sklearn.linear_model._stochastic_gradient.SGDClassifier),\n",
       " ('SVC', sklearn.svm._classes.SVC),\n",
       " ('StackingClassifier', sklearn.ensemble._stacking.StackingClassifier),\n",
       " ('VotingClassifier', sklearn.ensemble._voting.VotingClassifier)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필터 타입에 해당하는 sklearn에 존재하는 모든 모델 이름과 객체 리스트로 반환\n",
    "models = all_estimators(type_filter = 'classifier')\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 각 모델들 훈련시키고 정확도 추출\n",
    "scores = []\n",
    "for name, model in models:\n",
    "    try:\n",
    "        # 모델 객체 생성\n",
    "        md = model()\n",
    "        # 학습\n",
    "        md.fit(train_input, train_target)\n",
    "        # 평가\n",
    "        result = md.score(test_input, test_target)\n",
    "    \n",
    "        scores.append((name, result))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AdaBoostClassifier', 1.0),\n",
       " ('BaggingClassifier', 1.0),\n",
       " ('BernoulliNB', 0.36666666666666664),\n",
       " ('CalibratedClassifierCV', 0.9),\n",
       " ('CategoricalNB', 0.9666666666666667),\n",
       " ('ComplementNB', 0.7),\n",
       " ('DecisionTreeClassifier', 0.9333333333333333),\n",
       " ('DummyClassifier', 0.36666666666666664),\n",
       " ('ExtraTreeClassifier', 0.9666666666666667),\n",
       " ('ExtraTreesClassifier', 1.0),\n",
       " ('GaussianNB', 1.0),\n",
       " ('GaussianProcessClassifier', 1.0),\n",
       " ('GradientBoostingClassifier', 1.0),\n",
       " ('HistGradientBoostingClassifier', 0.9666666666666667),\n",
       " ('KNeighborsClassifier', 0.9666666666666667),\n",
       " ('LabelPropagation', 1.0),\n",
       " ('LabelSpreading', 1.0),\n",
       " ('LinearDiscriminantAnalysis', 1.0),\n",
       " ('LinearSVC', 1.0),\n",
       " ('LogisticRegression', 1.0),\n",
       " ('LogisticRegressionCV', 1.0),\n",
       " ('MLPClassifier', 0.9666666666666667),\n",
       " ('MultinomialNB', 0.7666666666666667),\n",
       " ('NearestCentroid', 0.9666666666666667),\n",
       " ('NuSVC', 1.0),\n",
       " ('PassiveAggressiveClassifier', 0.8),\n",
       " ('Perceptron', 0.9333333333333333),\n",
       " ('QuadraticDiscriminantAnalysis', 0.9666666666666667),\n",
       " ('RadiusNeighborsClassifier', 1.0),\n",
       " ('RandomForestClassifier', 1.0),\n",
       " ('RidgeClassifier', 0.9),\n",
       " ('RidgeClassifierCV', 0.9),\n",
       " ('SGDClassifier', 1.0),\n",
       " ('SVC', 1.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 분류기 모듈명과 score\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation \n",
    "---\n",
    "- 가장 일반적으로 사용되는 교차 검증 방법. \n",
    "- 보통 회귀 모델에 사용, 데이터가 독립적이고 동일한 분포 가진 경우 사용\n",
    "\n",
    "- 훈련 데이터가 줄어드는 문제 및 데이터가 충분하지 않은 문제 해결\n",
    "- 테스트 데이터에 과대적합(Overfitting) 문제 해결 \n",
    "- 훈련 데이터를 동일 크기로 여러 조각 나눈 후 데이터를교차시켜훈련/검증 데이터로 활용\n",
    "\n",
    "##### [장점] \n",
    "- 모든 데이터셋을 훈련과 평가에 활용 가능=> 정확도 ▲  \n",
    "- 데이터부족 과소적합 방지\n",
    "- 평가용 데이터 편중 ▼ \n",
    "- 평가 결과에 일반화된 모델 생성\n",
    "\n",
    "##### [단점] \n",
    "- 훈련과 평가에 많은 시간 소요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross_validate()함수 사용\n",
    "    - 기본값 cv = 5-Fold ===>모델 5개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris 데이터 불러오기\n",
    "data = load_iris()\n",
    "\n",
    "# data, target 데이터 받기\n",
    "input_data = data['data']\n",
    "input_target = data['target']\n",
    "\n",
    "# data, target 형태 확인\n",
    "input_data.shape, input_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape, input_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성\n",
    "model_LR = LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold로 5등분으로 나누어서 학습/검증 모델 생성 진행\n",
    "result = cross_validate(model_LR, input_data, input_target, return_train_score= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02950907, 0.0341084 , 0.08168006, 0.04094005, 0.02259016]),\n",
       " 'score_time': array([0.00086188, 0.00104499, 0.00055957, 0.00040317, 0.00040197]),\n",
       " 'test_score': array([0.96666667, 1.        , 0.93333333, 0.96666667, 1.        ]),\n",
       " 'train_score': array([0.96666667, 0.96666667, 0.98333333, 0.98333333, 0.975     ])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "print(result['test_score'].mean())\n",
    "print(result['train_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
